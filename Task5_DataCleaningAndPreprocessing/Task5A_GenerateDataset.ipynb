{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "252d4234-4b70-4189-8c28-d2059d34cc2d",
   "metadata": {},
   "source": [
    "# Data Cleaning & Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d55d5b0-dcb4-422f-8ac0-ede92d89fae8",
   "metadata": {},
   "source": [
    "## Generating Synthetic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63965e08-c5d2-48a5-8d1e-2df45d5ead7f",
   "metadata": {},
   "source": [
    "### Dataset Overview\n",
    "Shape: 1,500 records with 18 columns - a substantial dataset for cleaning practice!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "45ecd7ad-5119-465c-8eb3-d744b158faf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dirty internship application dataset for cleaning practice...\n",
      "Dirty dataset successfully saved as 'dirty_internship_applications.csv'\n",
      "Dataset shape: (1500, 19)\n",
      "\n",
      "================================================================================\n",
      "DATA QUALITY ISSUES SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total records: 1,500\n",
      "\n",
      "=== MISSING VALUES ANALYSIS ===\n",
      "                     Missing Count  Missing Percentage\n",
      "applicant_id                    39                2.60\n",
      "first_name                      33                2.20\n",
      "last_name                       35                2.33\n",
      "email                           29                1.93\n",
      "phone_number                    35                2.33\n",
      "university                      37                2.47\n",
      "major                           34                2.27\n",
      "gpa                            149                9.93\n",
      "graduation_year                 35                2.33\n",
      "application_date                29                1.93\n",
      "position_applied                38                2.53\n",
      "years_of_experience            142                9.47\n",
      "skills                          35                2.33\n",
      "application_status              39                2.60\n",
      "salary_expectation             164               10.93\n",
      "availability                    36                2.40\n",
      "resume_submitted                38                2.53\n",
      "cover_letter                    42                2.80\n",
      "references_provided             37                2.47\n",
      "\n",
      "=== DATA TYPE ISSUES ===\n",
      "Column data types:\n",
      "applicant_id            object\n",
      "first_name              object\n",
      "last_name               object\n",
      "email                   object\n",
      "phone_number            object\n",
      "university              object\n",
      "major                   object\n",
      "gpa                     object\n",
      "graduation_year        float64\n",
      "application_date        object\n",
      "position_applied        object\n",
      "years_of_experience    float64\n",
      "skills                  object\n",
      "application_status      object\n",
      "salary_expectation      object\n",
      "availability            object\n",
      "resume_submitted        object\n",
      "cover_letter            object\n",
      "references_provided    float64\n",
      "dtype: object\n",
      "\n",
      "=== DUPLICATE RECORDS ===\n",
      "Exact duplicates: 36 (2.4%)\n",
      "Near-duplicates (by name/email): 345 (23.0%)\n",
      "\n",
      "=== INCONSISTENT FORMATTING EXAMPLES ===\n",
      "Email issues                       :   87 variations\n",
      "Phone format variations            : 1397 variations\n",
      "Date format variations             :  676 variations\n",
      "Status case inconsistencies        :    9 variations\n",
      "\n",
      "=== OUTLIER DETECTION ===\n",
      "years_of_experience      :  86 outliers (5.7%)\n",
      "references_provided      :   0 outliers (0.0%)\n",
      "\n",
      "=== SAMPLE OF DATA ISSUES ===\n",
      "First 10 records with various data quality problems:\n",
      "applicant_id first_name                      email   gpa application_date application_status\n",
      "    APP-0001       John       JOHN.LOPEZ@EMAIL.COM  4.43       2024-04-07       Under Review\n",
      "     APP0002    Matthew       matthew215@email.com   3.5       25-05-2024           Accepted\n",
      "    APP-0003    Michael   michael.miller@email.com  3.24       09-02-2024           Accepted\n",
      "   APP_0004A    Matthew       mrodriguez@email.com  3.89       01-03-2024       Under Review\n",
      "    APP-0005      David     miller.david@email.com  2.15       05/04/2024          rejected \n",
      "     APP0006     Sarah   anderson.sarah @email.com  3.41       24-02-2024          rejected \n",
      "    APP0007B     Amanda        amanda874@email.com  1.88       04/20/2024           Rejected\n",
      "   APP_0008A    Matthew williams.matthew@email.com   3.7       2024-03-08           Accepted\n",
      "    APP_0009      James     miller.james@email.com  3.07       01-03-2024           Rejected\n",
      "    APP-0010       Jane   rodriguez.jane@email.com  3.09       01-03-2024          Submitted\n",
      "\n",
      "Data cleaning script saved as 'data_cleaning_script.py'\n",
      "\n",
      "=== DATA CLEANING CHECKLIST ===\n",
      "✓ Handle missing values in GPA, experience, and salary fields\n",
      "✓ Standardize text formatting (names, universities, majors)\n",
      "✓ Fix inconsistent date formats\n",
      "✓ Clean and validate email addresses\n",
      "✓ Standardize phone number formats\n",
      "✓ Handle outliers in numerical fields\n",
      "✓ Remove duplicate records\n",
      "✓ Standardize categorical variables (application status)\n",
      "✓ Fix data type conversions\n",
      "✓ Create derived features for analysis\n",
      "\n",
      "Dataset ready for data cleaning practice!\n",
      "Use pandas functions like: drop_duplicates(), fillna(), astype(), str methods, datetime conversion\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import string\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def generate_dirty_internship_dataset(n_records=1500):\n",
    "    \"\"\"\n",
    "    Generate a realistic internship application dataset with common data quality issues\n",
    "    \"\"\"\n",
    "    \n",
    "    # Clean base data components\n",
    "    first_names = ['John', 'Jane', 'Michael', 'Sarah', 'David', 'Emily', 'Christopher', 'Jessica', \n",
    "                  'Matthew', 'Amanda', 'James', 'Elizabeth', 'Robert', 'Michelle', 'Daniel', 'Laura']\n",
    "    last_names = ['Smith', 'Johnson', 'Williams', 'Brown', 'Jones', 'Garcia', 'Miller', 'Davis',\n",
    "                 'Rodriguez', 'Martinez', 'Hernandez', 'Lopez', 'Gonzalez', 'Wilson', 'Anderson']\n",
    "    \n",
    "    universities = ['State University', 'Tech Institute', 'Liberal Arts College', 'Community College',\n",
    "                   'International University', 'Online University', 'Private College', 'Public University']\n",
    "    \n",
    "    majors = ['Computer Science', 'Business Administration', 'Engineering', 'Data Science', \n",
    "             'Marketing', 'Psychology', 'Biology', 'Economics', 'Mathematics', 'Communications']\n",
    "    \n",
    "    skills = ['Python', 'Java', 'SQL', 'JavaScript', 'Excel', 'R', 'Tableau', 'PowerPoint',\n",
    "             'Machine Learning', 'Data Analysis', 'Project Management', 'Communication']\n",
    "    \n",
    "    positions = ['Data Science Intern', 'Software Developer Intern', 'Marketing Intern', \n",
    "                'Research Assistant', 'Business Analyst Intern', 'UX Design Intern']\n",
    "    \n",
    "    # Generate base clean data\n",
    "    data = []\n",
    "    for i in range(n_records):\n",
    "        # Basic information with intentional inconsistencies\n",
    "        applicant_id = f\"APP{random.choice(['', '_', '-'])}{i+1:04d}{random.choice(['', 'A', 'B', ''])}\"\n",
    "        \n",
    "        # Name with various formatting issues\n",
    "        first_name = random.choice(first_names)\n",
    "        last_name = random.choice(last_names)\n",
    "        \n",
    "        # Introduce name variations\n",
    "        if random.random() < 0.1:\n",
    "            first_name = first_name.upper()\n",
    "        if random.random() < 0.08:\n",
    "            last_name = last_name.lower()\n",
    "        if random.random() < 0.05:\n",
    "            first_name = first_name + \" \"\n",
    "        \n",
    "        # Email with various formats and issues\n",
    "        email_formats = [\n",
    "            f\"{first_name.lower()}.{last_name.lower()}@email.com\",\n",
    "            f\"{first_name[0].lower()}{last_name.lower()}@email.com\", \n",
    "            f\"{first_name.lower()}{random.randint(1,999)}@email.com\",\n",
    "            f\"{last_name.lower()}.{first_name.lower()}@email.com\"\n",
    "        ]\n",
    "        email = random.choice(email_formats)\n",
    "        \n",
    "        # Introduce email issues\n",
    "        if random.random() < 0.06:\n",
    "            email = email.replace('@', ' at ')\n",
    "        if random.random() < 0.04:\n",
    "            email = email.upper()\n",
    "        \n",
    "        # Phone number with various formats\n",
    "        phone_formats = [\n",
    "            f\"({random.randint(200,999)}) {random.randint(200,999)}-{random.randint(1000,9999)}\",\n",
    "            f\"{random.randint(200,999)}-{random.randint(200,999)}-{random.randint(1000,9999)}\",\n",
    "            f\"+1{random.randint(200,999)}{random.randint(200,999)}{random.randint(1000,9999)}\",\n",
    "            f\"{random.randint(200,999)}.{random.randint(200,999)}.{random.randint(1000,9999)}\"\n",
    "        ]\n",
    "        phone = random.choice(phone_formats)\n",
    "        \n",
    "        # GPA with various issues\n",
    "        if random.random() < 0.08:  # Missing GPA\n",
    "            gpa = None\n",
    "        elif random.random() < 0.05:  # Out of range GPA\n",
    "            gpa = round(random.uniform(0, 5.5), 2)\n",
    "        elif random.random() < 0.04:  # Wrong format\n",
    "            gpa = f\"{random.randint(1,4)}.{random.randint(0,99)}\"\n",
    "        else:\n",
    "            gpa = round(np.random.normal(3.3, 0.4), 2)\n",
    "            gpa = max(0, min(4.0, gpa))\n",
    "        \n",
    "        # University with inconsistencies\n",
    "        university = random.choice(universities)\n",
    "        if random.random() < 0.07:\n",
    "            university = university.upper()\n",
    "        if random.random() < 0.05:\n",
    "            university = university + \" \"\n",
    "        \n",
    "        # Major with similar issues\n",
    "        major = random.choice(majors)\n",
    "        if random.random() < 0.06:\n",
    "            major = major.replace(' ', '_')\n",
    "        \n",
    "        # Application date with various formats and issues\n",
    "        base_date = datetime(2024, 1, 1) + timedelta(days=random.randint(0, 180))\n",
    "        date_formats = [\n",
    "            base_date.strftime('%Y-%m-%d'),\n",
    "            base_date.strftime('%m/%d/%Y'),\n",
    "            base_date.strftime('%d-%m-%Y'),\n",
    "            base_date.strftime('%b %d, %Y')\n",
    "        ]\n",
    "        application_date = random.choice(date_formats)\n",
    "        \n",
    "        # Introduce date issues\n",
    "        if random.random() < 0.04:\n",
    "            application_date = application_date.replace('2024', '2023')\n",
    "        if random.random() < 0.03:\n",
    "            application_date = \"Pending\"\n",
    "        \n",
    "        # Years of experience with outliers and missing values\n",
    "        if random.random() < 0.07:\n",
    "            years_experience = None\n",
    "        elif random.random() < 0.05:  # Extreme outliers\n",
    "            years_experience = random.randint(20, 50)\n",
    "        else:\n",
    "            years_experience = max(0, int(np.random.exponential(1.5)))\n",
    "        \n",
    "        # Skills with various formatting issues\n",
    "        num_skills = random.randint(1, 8)\n",
    "        applicant_skills = random.sample(skills, num_skills)\n",
    "        \n",
    "        # Introduce skill formatting issues\n",
    "        skills_text = \", \".join(applicant_skills)\n",
    "        if random.random() < 0.08:\n",
    "            skills_text = skills_text.upper()\n",
    "        if random.random() < 0.06:\n",
    "            skills_text = skills_text.replace(',', ';')\n",
    "        if random.random() < 0.05:\n",
    "            skills_text = skills_text + \", \"\n",
    "        if random.random() < 0.04:\n",
    "            skills_text = \"Various technical skills\"\n",
    "        \n",
    "        # Position applied with inconsistencies\n",
    "        position = random.choice(positions)\n",
    "        if random.random() < 0.07:\n",
    "            position = position.lower()\n",
    "        \n",
    "        # Status with various entries\n",
    "        status_options = ['Submitted', 'Under Review', 'Rejected', 'Accepted', 'Pending', \n",
    "                         'In Process', 'review', 'ACCEPTED', ' rejected ']\n",
    "        status = random.choice(status_options)\n",
    "        \n",
    "        # Salary expectations with outliers and missing values\n",
    "        if random.random() < 0.09:\n",
    "            salary_expectation = None\n",
    "        elif random.random() < 0.04:  # Extreme values\n",
    "            salary_expectation = random.randint(100000, 500000)\n",
    "        elif random.random() < 0.03:  # Text instead of number\n",
    "            salary_expectation = \"Negotiable\"\n",
    "        else:\n",
    "            salary_expectation = random.randint(15000, 40000)\n",
    "        \n",
    "        # Availability with various formats\n",
    "        availability_options = ['Immediate', '2 weeks', '1 month', '3 months', 'Flexible',\n",
    "                               'immediate', ' ASAP', '2-4 weeks ', 'Unknown']\n",
    "        availability = random.choice(availability_options)\n",
    "        \n",
    "        data.append({\n",
    "            'applicant_id': applicant_id,\n",
    "            'first_name': first_name,\n",
    "            'last_name': last_name,\n",
    "            'email': email,\n",
    "            'phone_number': phone,\n",
    "            'university': university,\n",
    "            'major': major,\n",
    "            'gpa': gpa,\n",
    "            'graduation_year': random.randint(2022, 2026),\n",
    "            'application_date': application_date,\n",
    "            'position_applied': position,\n",
    "            'years_of_experience': years_experience,\n",
    "            'skills': skills_text,\n",
    "            'application_status': status,\n",
    "            'salary_expectation': salary_expectation,\n",
    "            'availability': availability,\n",
    "            'resume_submitted': random.choice([True, False, 'Yes', 'No', 1, 0]),\n",
    "            'cover_letter': random.choice(['Yes', 'No', 'YES', 'no', True, False, '']),\n",
    "            'references_provided': random.randint(0, 5)\n",
    "        })\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    # Introduce duplicate records (approximately 5% duplicates)\n",
    "    duplicate_indices = random.sample(range(n_records), int(n_records * 0.05))\n",
    "    for idx in duplicate_indices:\n",
    "        if idx + 1 < len(df):\n",
    "            df.iloc[idx + 1] = df.iloc[idx].copy()\n",
    "            # Modify one field slightly to make near-duplicates\n",
    "            if random.random() < 0.5:\n",
    "                df.iloc[idx + 1, df.columns.get_loc('email')] = df.iloc[idx + 1]['email'].replace('@', f\"{random.randint(1,9)}@\")\n",
    "    \n",
    "    # Add some completely empty records\n",
    "    empty_indices = random.sample(range(n_records), int(n_records * 0.03))\n",
    "    for idx in empty_indices:\n",
    "        for col in df.columns:\n",
    "            if random.random() < 0.8:  # 80% chance to make field empty\n",
    "                df.iloc[idx, df.columns.get_loc(col)] = None\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the dirty dataset\n",
    "print(\"Generating dirty internship application dataset for cleaning practice...\")\n",
    "dirty_df = generate_dirty_internship_dataset(1500)\n",
    "\n",
    "# Save the dirty dataset\n",
    "dirty_filename = 'dirty_internship_applications.csv'\n",
    "dirty_df.to_csv(dirty_filename, index=False)\n",
    "\n",
    "print(f\"Dirty dataset successfully saved as '{dirty_filename}'\")\n",
    "print(f\"Dataset shape: {dirty_df.shape}\")\n",
    "\n",
    "# Display data quality issues summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"DATA QUALITY ISSUES SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nTotal records: {len(dirty_df):,}\")\n",
    "\n",
    "print(f\"\\n=== MISSING VALUES ANALYSIS ===\")\n",
    "missing_data = dirty_df.isnull().sum()\n",
    "missing_percent = (dirty_df.isnull().sum() / len(dirty_df)) * 100\n",
    "missing_summary = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_percent.round(2)\n",
    "})\n",
    "print(missing_summary[missing_summary['Missing Count'] > 0])\n",
    "\n",
    "print(f\"\\n=== DATA TYPE ISSUES ===\")\n",
    "print(\"Column data types:\")\n",
    "print(dirty_df.dtypes)\n",
    "\n",
    "print(f\"\\n=== DUPLICATE RECORDS ===\")\n",
    "duplicate_count = dirty_df.duplicated().sum()\n",
    "print(f\"Exact duplicates: {duplicate_count} ({duplicate_count/len(dirty_df):.1%})\")\n",
    "\n",
    "# Check for near-duplicates based on key fields\n",
    "key_columns = ['first_name', 'last_name', 'email']\n",
    "near_duplicates = dirty_df.duplicated(subset=key_columns).sum()\n",
    "print(f\"Near-duplicates (by name/email): {near_duplicates} ({near_duplicates/len(dirty_df):.1%})\")\n",
    "\n",
    "print(f\"\\n=== INCONSISTENT FORMATTING EXAMPLES ===\")\n",
    "formatting_issues = {\n",
    "    'Email issues': dirty_df['email'].str.contains(' at ').sum(),\n",
    "    'Phone format variations': len(dirty_df['phone_number'].unique()),\n",
    "    'Date format variations': len(dirty_df['application_date'].unique()),\n",
    "    'Status case inconsistencies': len(dirty_df['application_status'].str.lower().unique())\n",
    "}\n",
    "\n",
    "for issue, count in formatting_issues.items():\n",
    "    print(f\"{issue:<35}: {count:>4} variations\")\n",
    "\n",
    "print(f\"\\n=== OUTLIER DETECTION ===\")\n",
    "# Numerical columns outlier analysis\n",
    "numerical_cols = ['gpa', 'years_of_experience', 'salary_expectation', 'references_provided']\n",
    "for col in numerical_cols:\n",
    "    if dirty_df[col].dtype in ['int64', 'float64']:\n",
    "        Q1 = dirty_df[col].quantile(0.25)\n",
    "        Q3 = dirty_df[col].quantile(0.75)\n",
    "        IQR = Q3 - Q1\n",
    "        lower_bound = Q1 - 1.5 * IQR\n",
    "        upper_bound = Q3 + 1.5 * IQR\n",
    "        outliers = dirty_df[(dirty_df[col] < lower_bound) | (dirty_df[col] > upper_bound)][col].count()\n",
    "        print(f\"{col:<25}: {outliers:>3} outliers ({outliers/len(dirty_df):.1%})\")\n",
    "\n",
    "print(f\"\\n=== SAMPLE OF DATA ISSUES ===\")\n",
    "print(\"First 10 records with various data quality problems:\")\n",
    "sample_issues = dirty_df.head(10)[['applicant_id', 'first_name', 'email', 'gpa', 'application_date', 'application_status']]\n",
    "print(sample_issues.to_string(index=False))\n",
    "\n",
    "# Now create a cleaning script template\n",
    "cleaning_script = \"\"\"\n",
    "# DATA CLEANING AND PREPROCESSING SCRIPT\n",
    "# For internship_applications_dirty.csv\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def clean_internship_data(df):\n",
    "    \\\"\\\"\\\"Comprehensive data cleaning function\\\"\\\"\\\"\n",
    "    \n",
    "    # Create a copy to preserve original data\n",
    "    cleaned_df = df.copy()\n",
    "    \n",
    "    # 1. STANDARDIZE TEXT FIELDS\n",
    "    text_columns = ['first_name', 'last_name', 'university', 'major', 'position_applied']\n",
    "    for col in text_columns:\n",
    "        cleaned_df[col] = cleaned_df[col].astype(str).str.strip().str.title()\n",
    "    \n",
    "    # 2. CLEAN EMAIL ADDRESSES\n",
    "    cleaned_df['email'] = cleaned_df['email'].str.lower().str.replace(' at ', '@').str.strip()\n",
    "    \n",
    "    # 3. STANDARDIZE PHONE NUMBERS\n",
    "    # Remove non-numeric characters and format consistently\n",
    "    cleaned_df['phone_number'] = cleaned_df['phone_number'].astype(str).str.replace(r'\\\\D', '', regex=True)\n",
    "    \n",
    "    # 4. HANDLE MISSING VALUES\n",
    "    # GPA: Fill with mean or median\n",
    "    gpa_mean = pd.to_numeric(cleaned_df['gpa'], errors='coerce').mean()\n",
    "    cleaned_df['gpa'] = pd.to_numeric(cleaned_df['gpa'], errors='coerce').fillna(gpa_mean)\n",
    "    \n",
    "    # Years of experience: Fill with 0 for interns\n",
    "    cleaned_df['years_of_experience'] = cleaned_df['years_of_experience'].fillna(0)\n",
    "    \n",
    "    # 5. FIX DATA TYPES\n",
    "    cleaned_df['application_date'] = pd.to_datetime(cleaned_df['application_date'], errors='coerce')\n",
    "    cleaned_df['graduation_year'] = pd.to_numeric(cleaned_df['graduation_year'], errors='coerce')\n",
    "    \n",
    "    # 6. HANDLE OUTLIERS\n",
    "    # Cap unrealistic values\n",
    "    cleaned_df['gpa'] = cleaned_df['gpa'].clip(0, 4.0)\n",
    "    cleaned_df['years_of_experience'] = cleaned_df['years_of_experience'].clip(0, 10)\n",
    "    \n",
    "    # 7. STANDARDIZE CATEGORICAL VARIABLES\n",
    "    status_mapping = {'review': 'Under Review', 'accepted': 'Accepted', 'rejected': 'Rejected'}\n",
    "    cleaned_df['application_status'] = cleaned_df['application_status'].str.strip().str.title()\n",
    "    cleaned_df['application_status'] = cleaned_df['application_status'].replace(status_mapping)\n",
    "    \n",
    "    # 8. REMOVE DUPLICATES\n",
    "    cleaned_df = cleaned_df.drop_duplicates()\n",
    "    cleaned_df = cleaned_df.drop_duplicates(subset=['email', 'first_name', 'last_name'])\n",
    "    \n",
    "    # 9. CREATE DERIVED COLUMNS\n",
    "    cleaned_df['full_name'] = cleaned_df['first_name'] + ' ' + cleaned_df['last_name']\n",
    "    cleaned_df['days_since_application'] = (datetime.now() - cleaned_df['application_date']).dt.days\n",
    "    \n",
    "    return cleaned_df\n",
    "\n",
    "# Load and clean the data\n",
    "df = pd.read_csv('dirty_internship_applications.csv')\n",
    "cleaned_df = clean_internship_data(df)\n",
    "\n",
    "print(\"Data cleaning completed!\")\n",
    "print(f\"Original shape: {df.shape}\")\n",
    "print(f\"Cleaned shape: {cleaned_df.shape}\")\n",
    "\"\"\"\n",
    "\n",
    "# Save cleaning script\n",
    "script_filename = 'data_cleaning_script.py'\n",
    "with open(script_filename, 'w') as f:\n",
    "    f.write(cleaning_script)\n",
    "\n",
    "print(f\"\\nData cleaning script saved as '{script_filename}'\")\n",
    "\n",
    "print(f\"\\n=== DATA CLEANING CHECKLIST ===\")\n",
    "cleaning_tasks = [\n",
    "    \"✓ Handle missing values in GPA, experience, and salary fields\",\n",
    "    \"✓ Standardize text formatting (names, universities, majors)\",\n",
    "    \"✓ Fix inconsistent date formats\",\n",
    "    \"✓ Clean and validate email addresses\", \n",
    "    \"✓ Standardize phone number formats\",\n",
    "    \"✓ Handle outliers in numerical fields\",\n",
    "    \"✓ Remove duplicate records\",\n",
    "    \"✓ Standardize categorical variables (application status)\",\n",
    "    \"✓ Fix data type conversions\",\n",
    "    \"✓ Create derived features for analysis\"\n",
    "]\n",
    "\n",
    "for task in cleaning_tasks:\n",
    "    print(task)\n",
    "\n",
    "print(f\"\\nDataset ready for data cleaning practice!\")\n",
    "print(f\"Use pandas functions like: drop_duplicates(), fillna(), astype(), str methods, datetime conversion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ca6efc-7a96-4d0b-b1a3-9c238a2c2808",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
