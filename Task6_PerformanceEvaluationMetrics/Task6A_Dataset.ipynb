{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f89812d2-6c74-4bc4-aedc-d73d3adf6a7a",
   "metadata": {},
   "source": [
    "# Performance Evaluation Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0139861a-5883-42e9-851f-bf2fa2e3c341",
   "metadata": {},
   "source": [
    "## Generating Synthetic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ada5ae4e-16ab-45df-9423-7a6f5a6108fd",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "Your dataset contains 4 interconnected tables:\n",
    "\n",
    "Monthly Performance Metrics (600 records)\n",
    "\n",
    "Task-level Details (~4,800 records)\n",
    "\n",
    "Detailed Feedback (3,000 records)\n",
    "\n",
    "Intern Information (100 records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b00d1b8-1e95-4077-a998-8e4efd31a093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating intern performance evaluation dataset...\n",
      "Performance evaluation datasets saved successfully!\n",
      "Monthly performance metrics: (600, 17)\n",
      "Task-level details: (5098, 12)\n",
      "Feedback details: (3000, 8)\n",
      "Intern information: (100, 5)\n",
      "\n",
      "================================================================================\n",
      "INTERN PERFORMANCE EVALUATION METRICS - SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "=== DATASET OVERVIEW ===\n",
      "Total interns: 100\n",
      "Evaluation period: 6 months\n",
      "Total task records: 5,098\n",
      "Total feedback entries: 3,000\n",
      "\n",
      "=== KEY PERFORMANCE INDICATORS (KPIs) ===\n",
      "Average Completion Rate            : 77.0%\n",
      "Average Task Quality Score         : 7.1/10\n",
      "Average Mentor Feedback            : 7.6/10\n",
      "Average Completion Time            : 4.4 days\n",
      "Overall Performance Score          : 424.3/100\n",
      "\n",
      "=== PERFORMANCE BY TIER ===\n",
      "                  Completion%  Quality  Feedback  Perf_Score  Records\n",
      "performance_tier                                                     \n",
      "Exceptional              85.0      8.9       9.4       522.5       84\n",
      "High                     84.7      8.0       8.5       479.7      204\n",
      "Low                      69.1      4.9       5.6       313.1      102\n",
      "Medium                   70.1      6.5       7.1       385.2      210\n",
      "\n",
      "=== DEPARTMENT-WISE PERFORMANCE ===\n",
      "                      Avg_Completion%  Avg_Quality  Avg_Perf_Score  \\\n",
      "department                                                           \n",
      "Business Analytics               76.0          6.8           404.4   \n",
      "Data Science                     77.9          7.3           430.7   \n",
      "Marketing                        76.8          7.0           423.9   \n",
      "Software Engineering             78.1          7.4           443.2   \n",
      "UX Design                        76.4          7.2           429.9   \n",
      "\n",
      "                      Intern_Count  \n",
      "department                          \n",
      "Business Analytics              25  \n",
      "Data Science                    25  \n",
      "Marketing                       19  \n",
      "Software Engineering            13  \n",
      "UX Design                       18  \n",
      "\n",
      "=== TASK PERFORMANCE ANALYSIS ===\n",
      "                  Avg_Hours  Avg_Quality  Avg_Days  Task_Count\n",
      "task_type                                                     \n",
      "Code Development       11.9          7.2       3.8         721\n",
      "Data Analysis           8.1          7.2       3.8         749\n",
      "Documentation           3.0          7.1       3.9         694\n",
      "Presentation            5.0          7.3       3.7         692\n",
      "Report Writing          6.0          7.2       3.8         728\n",
      "Research               10.2          7.3       3.7         770\n",
      "Testing                 4.0          7.1       3.8         744\n",
      "\n",
      "=== MONTHLY TREND ANALYSIS ===\n",
      "       completion_rate  avg_quality_score  monthly_performance_score\n",
      "month                                                               \n",
      "1                 78.7                7.1                      423.9\n",
      "2                 75.8                7.0                      421.3\n",
      "3                 75.7                7.0                      422.2\n",
      "4                 75.8                7.3                      429.3\n",
      "5                 78.9                7.2                      425.9\n",
      "6                 76.9                7.0                      423.0\n",
      "\n",
      "=== FEEDBACK CATEGORY ANALYSIS ===\n",
      "                   mean   std  count\n",
      "feedback_category                   \n",
      "Communication      7.61  1.50    600\n",
      "Initiative         7.62  1.53    600\n",
      "Problem Solving    7.62  1.47    600\n",
      "Teamwork           7.60  1.54    600\n",
      "Technical Skills   7.59  1.55    600\n",
      "\n",
      "=== AUTOMATED REPORTING CAPABILITIES ===\n",
      "✓ Monthly department-wise performance reports\n",
      "✓ Individual intern progress tracking\n",
      "✓ Task completion efficiency analysis\n",
      "✓ Mentor feedback trend analysis\n",
      "✓ Performance tier distribution reports\n",
      "✓ Custom KPI dashboards\n",
      "✓ SQL queries for automated extraction\n",
      "✓ Python scripts for data processing\n",
      "\n",
      "=== SAMPLE MONTHLY REPORT DATA ===\n",
      "Last month's performance snapshot:\n",
      "intern_id           department  completion_rate  avg_quality_score  monthly_performance_score\n",
      " INT_0001         Data Science             67.8                7.0                      370.7\n",
      " INT_0002 Software Engineering             81.8                4.8                      385.0\n",
      " INT_0003   Business Analytics             57.6                8.0                      437.5\n",
      " INT_0004         Data Science             94.8                8.0                      494.3\n",
      " INT_0005   Business Analytics             84.8                5.9                      381.1\n",
      "\n",
      "Performance reporting scripts saved!\n",
      "✓ SQL queries: 'performance_reporting_queries.sql'\n",
      "✓ Python script: 'performance_reporting_script.py'\n",
      "\n",
      "Dataset ready for performance evaluation and automated reporting!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def generate_performance_evaluation_dataset(n_interns=100, months=6):\n",
    "    \"\"\"\n",
    "    Generate a comprehensive intern performance evaluation dataset with KPIs\n",
    "    \"\"\"\n",
    "    \n",
    "    # Intern base information\n",
    "    departments = ['Data Science', 'Software Engineering', 'Marketing', 'UX Design', 'Business Analytics']\n",
    "    mentors = ['Dr. Smith', 'Prof. Johnson', 'Dr. Williams', 'Prof. Brown', 'Dr. Davis', 'Prof. Miller']\n",
    "    \n",
    "    # Performance tiers and characteristics\n",
    "    performance_tiers = ['Exceptional', 'High', 'Medium', 'Low']\n",
    "    tier_characteristics = {\n",
    "        'Exceptional': {'task_time_mean': 2, 'task_time_std': 0.5, 'quality_mean': 9, 'feedback_mean': 9.5},\n",
    "        'High': {'task_time_mean': 3, 'task_time_std': 1, 'quality_mean': 8, 'feedback_mean': 8.5},\n",
    "        'Medium': {'task_time_mean': 5, 'task_time_std': 1.5, 'quality_mean': 6.5, 'feedback_mean': 7},\n",
    "        'Low': {'task_time_mean': 8, 'task_time_std': 2, 'quality_mean': 5, 'feedback_mean': 5.5}\n",
    "    }\n",
    "    \n",
    "    # Task types with different complexity levels\n",
    "    task_types = {\n",
    "        'Data Analysis': {'complexity': 3, 'expected_hours': 8},\n",
    "        'Code Development': {'complexity': 4, 'expected_hours': 12},\n",
    "        'Report Writing': {'complexity': 2, 'expected_hours': 6},\n",
    "        'Research': {'complexity': 3, 'expected_hours': 10},\n",
    "        'Presentation': {'complexity': 2, 'expected_hours': 5},\n",
    "        'Testing': {'complexity': 2, 'expected_hours': 4},\n",
    "        'Documentation': {'complexity': 1, 'expected_hours': 3}\n",
    "    }\n",
    "    \n",
    "    # Generate intern base data\n",
    "    interns = []\n",
    "    for i in range(n_interns):\n",
    "        intern_id = f\"INT_{i+1:04d}\"\n",
    "        department = random.choice(departments)\n",
    "        mentor = random.choice(mentors)\n",
    "        \n",
    "        # Assign performance tier with some distribution\n",
    "        tier_weights = [0.15, 0.35, 0.35, 0.15]  # More in middle tiers\n",
    "        performance_tier = random.choices(performance_tiers, weights=tier_weights)[0]\n",
    "        \n",
    "        interns.append({\n",
    "            'intern_id': intern_id,\n",
    "            'department': department,\n",
    "            'mentor': mentor,\n",
    "            'performance_tier': performance_tier,\n",
    "            'join_date': datetime(2024, 1, 1) + timedelta(days=random.randint(0, 30))\n",
    "        })\n",
    "    \n",
    "    # Generate monthly performance data\n",
    "    performance_data = []\n",
    "    task_data = []\n",
    "    feedback_data = []\n",
    "    \n",
    "    for intern in interns:\n",
    "        intern_id = intern['intern_id']\n",
    "        tier = intern['performance_tier']\n",
    "        characteristics = tier_characteristics[tier]\n",
    "        \n",
    "        for month in range(1, months + 1):\n",
    "            # Monthly summary metrics\n",
    "            year = 2024\n",
    "            month_start = datetime(year, month, 1)\n",
    "            \n",
    "            # Tasks completed this month (varies by performance)\n",
    "            base_tasks = 10 if tier in ['Exceptional', 'High'] else 8\n",
    "            tasks_completed = max(4, int(np.random.normal(base_tasks, 2)))\n",
    "            \n",
    "            # Task completion rate (percentage of assigned tasks completed)\n",
    "            completion_rate = np.random.normal(0.85 if tier in ['Exceptional', 'High'] else 0.70, 0.1)\n",
    "            completion_rate = max(0.5, min(1.0, completion_rate))\n",
    "            \n",
    "            # Average task completion time (days)\n",
    "            avg_completion_time = np.random.normal(characteristics['task_time_mean'], characteristics['task_time_std'])\n",
    "            avg_completion_time = max(1, avg_completion_time)\n",
    "            \n",
    "            # Quality score (1-10 scale)\n",
    "            avg_quality_score = np.random.normal(characteristics['quality_mean'], 1)\n",
    "            avg_quality_score = max(1, min(10, avg_quality_score))\n",
    "            \n",
    "            # Mentor feedback score (1-10 scale)\n",
    "            mentor_feedback = np.random.normal(characteristics['feedback_mean'], 0.8)\n",
    "            mentor_feedback = max(1, min(10, mentor_feedback))\n",
    "            \n",
    "            # Initiative and learning metrics\n",
    "            initiatives_taken = random.randint(1, 5) if tier in ['Exceptional', 'High'] else random.randint(0, 2)\n",
    "            learning_assessments = np.random.normal(75, 15) if tier in ['Exceptional', 'High'] else np.random.normal(60, 20)\n",
    "            learning_assessments = max(0, min(100, learning_assessments))\n",
    "            \n",
    "            # Collaboration metrics\n",
    "            collaboration_score = np.random.normal(8, 1) if tier in ['Exceptional', 'High'] else np.random.normal(6, 1.5)\n",
    "            collaboration_score = max(1, min(10, collaboration_score))\n",
    "            \n",
    "            # Monthly performance score (composite KPI)\n",
    "            monthly_score = (\n",
    "                completion_rate * 25 +\n",
    "                (1 / avg_completion_time) * 20 +\n",
    "                avg_quality_score * 25 +\n",
    "                mentor_feedback * 20 +\n",
    "                collaboration_score * 10\n",
    "            )\n",
    "            \n",
    "            performance_data.append({\n",
    "                'intern_id': intern_id,\n",
    "                'year': year,\n",
    "                'month': month,\n",
    "                'month_start': month_start.strftime('%Y-%m-%d'),\n",
    "                'tasks_completed': tasks_completed,\n",
    "                'tasks_assigned': int(tasks_completed / completion_rate),\n",
    "                'completion_rate': round(completion_rate * 100, 1),\n",
    "                'avg_completion_time_days': round(avg_completion_time, 1),\n",
    "                'avg_quality_score': round(avg_quality_score, 1),\n",
    "                'mentor_feedback_score': round(mentor_feedback, 1),\n",
    "                'initiatives_taken': initiatives_taken,\n",
    "                'learning_assessment_score': round(learning_assessments, 1),\n",
    "                'collaboration_score': round(collaboration_score, 1),\n",
    "                'monthly_performance_score': round(monthly_score, 1),\n",
    "                'performance_tier': tier,\n",
    "                'department': intern['department'],\n",
    "                'mentor': intern['mentor']\n",
    "            })\n",
    "            \n",
    "            # Generate detailed task data for this month\n",
    "            for task_num in range(tasks_completed):\n",
    "                task_type = random.choice(list(task_types.keys()))\n",
    "                task_complexity = task_types[task_type]['complexity']\n",
    "                expected_hours = task_types[task_type]['expected_hours']\n",
    "                \n",
    "                # Actual performance varies by intern tier\n",
    "                tier_factor = {'Exceptional': 0.8, 'High': 0.9, 'Medium': 1.1, 'Low': 1.3}[tier]\n",
    "                actual_hours = expected_hours * np.random.normal(tier_factor, 0.2)\n",
    "                \n",
    "                # Task completion status\n",
    "                completion_status = random.choices(\n",
    "                    ['Completed Early', 'Completed On Time', 'Completed Late', 'Extended'],\n",
    "                    weights=[0.3, 0.5, 0.15, 0.05]\n",
    "                )[0]\n",
    "                \n",
    "                # Quality score for this task\n",
    "                task_quality = np.random.normal(avg_quality_score, 1)\n",
    "                task_quality = max(1, min(10, task_quality))\n",
    "                \n",
    "                task_data.append({\n",
    "                    'task_id': f\"{intern_id}_M{month}_T{task_num+1:02d}\",\n",
    "                    'intern_id': intern_id,\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'task_type': task_type,\n",
    "                    'task_complexity': task_complexity,\n",
    "                    'expected_hours': expected_hours,\n",
    "                    'actual_hours': max(1, round(actual_hours, 1)),\n",
    "                    'completion_status': completion_status,\n",
    "                    'quality_score': round(task_quality, 1),\n",
    "                    'days_to_complete': max(1, int(np.random.normal(avg_completion_time, 1))),\n",
    "                    'department': intern['department']\n",
    "                })\n",
    "            \n",
    "            # Generate detailed feedback data\n",
    "            feedback_categories = ['Technical Skills', 'Communication', 'Problem Solving', 'Teamwork', 'Initiative']\n",
    "            for category in feedback_categories:\n",
    "                base_score = mentor_feedback\n",
    "                category_score = np.random.normal(base_score, 0.5)\n",
    "                category_score = max(1, min(10, category_score))\n",
    "                \n",
    "                feedback_data.append({\n",
    "                    'feedback_id': f\"{intern_id}_M{month}_{category[:3]}\",\n",
    "                    'intern_id': intern_id,\n",
    "                    'year': year,\n",
    "                    'month': month,\n",
    "                    'feedback_category': category,\n",
    "                    'score': round(category_score, 1),\n",
    "                    'mentor': intern['mentor'],\n",
    "                    'comments': generate_feedback_comment(category_score, category)\n",
    "                })\n",
    "    \n",
    "    return {\n",
    "        'monthly_performance': pd.DataFrame(performance_data),\n",
    "        'task_details': pd.DataFrame(task_data),\n",
    "        'feedback_details': pd.DataFrame(feedback_data),\n",
    "        'intern_info': pd.DataFrame(interns)\n",
    "    }\n",
    "\n",
    "def generate_feedback_comment(score, category):\n",
    "    \"\"\"Generate realistic feedback comments based on score\"\"\"\n",
    "    if score >= 9:\n",
    "        comments = [\n",
    "            f\"Exceptional {category.lower()}, consistently exceeds expectations\",\n",
    "            f\"Outstanding performance in {category.lower()}, great initiative\",\n",
    "            f\"Excellent {category.lower()}, demonstrates advanced skills\"\n",
    "        ]\n",
    "    elif score >= 7:\n",
    "        comments = [\n",
    "            f\"Strong {category.lower()}, meets all expectations\",\n",
    "            f\"Good performance in {category.lower()}, reliable and consistent\",\n",
    "            f\"Solid {category.lower()} skills, continues to improve\"\n",
    "        ]\n",
    "    elif score >= 5:\n",
    "        comments = [\n",
    "            f\"Adequate {category.lower()}, has room for improvement\",\n",
    "            f\"Developing {category.lower()} skills, needs more practice\",\n",
    "            f\"Average performance in {category.lower()}, working on improvements\"\n",
    "        ]\n",
    "    else:\n",
    "        comments = [\n",
    "            f\"Needs significant improvement in {category.lower()}\",\n",
    "            f\"Struggling with {category.lower()}, requires additional support\",\n",
    "            f\"Below expectations in {category.lower()}, needs focused training\"\n",
    "        ]\n",
    "    return random.choice(comments)\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Generating intern performance evaluation dataset...\")\n",
    "dataset = generate_performance_evaluation_dataset(n_interns=100, months=6)\n",
    "\n",
    "# Save individual datasets\n",
    "dataset['monthly_performance'].to_csv('monthly_performance_metrics.csv', index=False)\n",
    "dataset['task_details'].to_csv('task_level_metrics.csv', index=False)\n",
    "dataset['feedback_details'].to_csv('detailed_feedback.csv', index=False)\n",
    "dataset['intern_info'].to_csv('intern_information.csv', index=False)\n",
    "\n",
    "print(\"Performance evaluation datasets saved successfully!\")\n",
    "print(f\"Monthly performance metrics: {dataset['monthly_performance'].shape}\")\n",
    "print(f\"Task-level details: {dataset['task_details'].shape}\")\n",
    "print(f\"Feedback details: {dataset['feedback_details'].shape}\")\n",
    "print(f\"Intern information: {dataset['intern_info'].shape}\")\n",
    "\n",
    "# Generate comprehensive summary report\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERN PERFORMANCE EVALUATION METRICS - SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "monthly_df = dataset['monthly_performance']\n",
    "task_df = dataset['task_details']\n",
    "feedback_df = dataset['feedback_details']\n",
    "\n",
    "print(f\"\\n=== DATASET OVERVIEW ===\")\n",
    "print(f\"Total interns: {monthly_df['intern_id'].nunique()}\")\n",
    "print(f\"Evaluation period: {monthly_df['month'].nunique()} months\")\n",
    "print(f\"Total task records: {len(task_df):,}\")\n",
    "print(f\"Total feedback entries: {len(feedback_df):,}\")\n",
    "\n",
    "print(f\"\\n=== KEY PERFORMANCE INDICATORS (KPIs) ===\")\n",
    "kpis = {\n",
    "    'Average Completion Rate': f\"{monthly_df['completion_rate'].mean():.1f}%\",\n",
    "    'Average Task Quality Score': f\"{monthly_df['avg_quality_score'].mean():.1f}/10\",\n",
    "    'Average Mentor Feedback': f\"{monthly_df['mentor_feedback_score'].mean():.1f}/10\",\n",
    "    'Average Completion Time': f\"{monthly_df['avg_completion_time_days'].mean():.1f} days\",\n",
    "    'Overall Performance Score': f\"{monthly_df['monthly_performance_score'].mean():.1f}/100\"\n",
    "}\n",
    "\n",
    "for kpi, value in kpis.items():\n",
    "    print(f\"{kpi:<35}: {value}\")\n",
    "\n",
    "print(f\"\\n=== PERFORMANCE BY TIER ===\")\n",
    "tier_performance = monthly_df.groupby('performance_tier').agg({\n",
    "    'completion_rate': 'mean',\n",
    "    'avg_quality_score': 'mean',\n",
    "    'mentor_feedback_score': 'mean',\n",
    "    'monthly_performance_score': 'mean',\n",
    "    'intern_id': 'count'\n",
    "}).round(1)\n",
    "\n",
    "tier_performance.columns = ['Completion%', 'Quality', 'Feedback', 'Perf_Score', 'Records']\n",
    "print(tier_performance)\n",
    "\n",
    "print(f\"\\n=== DEPARTMENT-WISE PERFORMANCE ===\")\n",
    "dept_performance = monthly_df.groupby('department').agg({\n",
    "    'completion_rate': 'mean',\n",
    "    'avg_quality_score': 'mean',\n",
    "    'monthly_performance_score': 'mean',\n",
    "    'intern_id': 'nunique'\n",
    "}).round(1)\n",
    "\n",
    "dept_performance.columns = ['Avg_Completion%', 'Avg_Quality', 'Avg_Perf_Score', 'Intern_Count']\n",
    "print(dept_performance)\n",
    "\n",
    "print(f\"\\n=== TASK PERFORMANCE ANALYSIS ===\")\n",
    "task_analysis = task_df.groupby('task_type').agg({\n",
    "    'actual_hours': 'mean',\n",
    "    'quality_score': 'mean',\n",
    "    'days_to_complete': 'mean',\n",
    "    'task_id': 'count'\n",
    "}).round(1)\n",
    "\n",
    "task_analysis.columns = ['Avg_Hours', 'Avg_Quality', 'Avg_Days', 'Task_Count']\n",
    "print(task_analysis)\n",
    "\n",
    "print(f\"\\n=== MONTHLY TREND ANALYSIS ===\")\n",
    "monthly_trend = monthly_df.groupby('month').agg({\n",
    "    'completion_rate': 'mean',\n",
    "    'avg_quality_score': 'mean',\n",
    "    'monthly_performance_score': 'mean'\n",
    "}).round(1)\n",
    "\n",
    "print(monthly_trend)\n",
    "\n",
    "print(f\"\\n=== FEEDBACK CATEGORY ANALYSIS ===\")\n",
    "feedback_analysis = feedback_df.groupby('feedback_category')['score'].agg(['mean', 'std', 'count']).round(2)\n",
    "print(feedback_analysis)\n",
    "\n",
    "# Generate SQL queries for automated reporting\n",
    "sql_queries = \"\"\"\n",
    "-- MONTHLY PERFORMANCE REPORT QUERY\n",
    "SELECT \n",
    "    department,\n",
    "    month,\n",
    "    AVG(completion_rate) as avg_completion_rate,\n",
    "    AVG(avg_quality_score) as avg_quality_score,\n",
    "    AVG(mentor_feedback_score) as avg_feedback_score,\n",
    "    AVG(monthly_performance_score) as overall_score,\n",
    "    COUNT(DISTINCT intern_id) as intern_count\n",
    "FROM monthly_performance_metrics \n",
    "WHERE year = 2024 \n",
    "GROUP BY department, month \n",
    "ORDER BY department, month;\n",
    "\n",
    "-- TOP PERFORMERS QUERY\n",
    "SELECT \n",
    "    intern_id,\n",
    "    department,\n",
    "    AVG(monthly_performance_score) as avg_performance_score,\n",
    "    AVG(completion_rate) as avg_completion_rate\n",
    "FROM monthly_performance_metrics \n",
    "GROUP BY intern_id, department \n",
    "HAVING AVG(monthly_performance_score) > 80 \n",
    "ORDER BY avg_performance_score DESC;\n",
    "\n",
    "-- TASK COMPLETION ANALYSIS\n",
    "SELECT \n",
    "    task_type,\n",
    "    completion_status,\n",
    "    COUNT(*) as task_count,\n",
    "    AVG(actual_hours) as avg_hours,\n",
    "    AVG(quality_score) as avg_quality\n",
    "FROM task_level_metrics \n",
    "GROUP BY task_type, completion_status \n",
    "ORDER BY task_type, completion_status;\n",
    "\"\"\"\n",
    "\n",
    "# Save SQL queries\n",
    "with open('performance_reporting_queries.sql', 'w') as f:\n",
    "    f.write(sql_queries)\n",
    "\n",
    "print(f\"\\n=== AUTOMATED REPORTING CAPABILITIES ===\")\n",
    "reporting_features = [\n",
    "    \"✓ Monthly department-wise performance reports\",\n",
    "    \"✓ Individual intern progress tracking\", \n",
    "    \"✓ Task completion efficiency analysis\",\n",
    "    \"✓ Mentor feedback trend analysis\",\n",
    "    \"✓ Performance tier distribution reports\",\n",
    "    \"✓ Custom KPI dashboards\",\n",
    "    \"✓ SQL queries for automated extraction\",\n",
    "    \"✓ Python scripts for data processing\"\n",
    "]\n",
    "\n",
    "for feature in reporting_features:\n",
    "    print(feature)\n",
    "\n",
    "print(f\"\\n=== SAMPLE MONTHLY REPORT DATA ===\")\n",
    "print(\"Last month's performance snapshot:\")\n",
    "last_month = monthly_df[monthly_df['month'] == 6].head(5)\n",
    "print(last_month[['intern_id', 'department', 'completion_rate', 'avg_quality_score', 'monthly_performance_score']].to_string(index=False))\n",
    "\n",
    "# Create Python automation script\n",
    "python_script = \"\"\"\n",
    "# PERFORMANCE METRICS AUTOMATION SCRIPT\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_monthly_report(month, year=2024):\n",
    "    \\\"\\\"\\\"Generate monthly performance report for supervisors\\\"\\\"\\\"\n",
    "    \n",
    "    # Load datasets\n",
    "    monthly_df = pd.read_csv('monthly_performance_metrics.csv')\n",
    "    task_df = pd.read_csv('task_level_metrics.csv')\n",
    "    feedback_df = pd.read_csv('detailed_feedback.csv')\n",
    "    \n",
    "    # Filter for specific month\n",
    "    monthly_data = monthly_df[(monthly_df['month'] == month) & (monthly_df['year'] == year)]\n",
    "    \n",
    "    # Generate summary statistics\n",
    "    report = {\n",
    "        'report_month': f\"{year}-{month:02d}\",\n",
    "        'total_interns': monthly_data['intern_id'].nunique(),\n",
    "        'avg_completion_rate': monthly_data['completion_rate'].mean(),\n",
    "        'avg_quality_score': monthly_data['avg_quality_score'].mean(),\n",
    "        'avg_performance_score': monthly_data['monthly_performance_score'].mean(),\n",
    "        'top_performing_dept': monthly_data.groupby('department')['monthly_performance_score'].mean().idxmax()\n",
    "    }\n",
    "    \n",
    "    # Department-wise breakdown\n",
    "    dept_breakdown = monthly_data.groupby('department').agg({\n",
    "        'monthly_performance_score': 'mean',\n",
    "        'completion_rate': 'mean',\n",
    "        'intern_id': 'count'\n",
    "    }).round(2)\n",
    "    \n",
    "    return report, dept_breakdown\n",
    "\n",
    "def calculate_kpi_trends():\n",
    "    \\\"\\\"\\\"Calculate month-over-month KPI trends\\\"\\\"\\\"\n",
    "    monthly_df = pd.read_csv('monthly_performance_metrics.csv')\n",
    "    \n",
    "    trends = monthly_df.groupby('month').agg({\n",
    "        'completion_rate': 'mean',\n",
    "        'avg_quality_score': 'mean', \n",
    "        'monthly_performance_score': 'mean'\n",
    "    })\n",
    "    \n",
    "    return trends\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate report for latest month\n",
    "    report, breakdown = generate_monthly_report(6)\n",
    "    print(\"Monthly Performance Report:\")\n",
    "    for key, value in report.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    print(\"\\\\nDepartment Breakdown:\")\n",
    "    print(breakdown)\n",
    "\"\"\"\n",
    "\n",
    "with open('performance_reporting_script.py', 'w') as f:\n",
    "    f.write(python_script)\n",
    "\n",
    "print(f\"\\nPerformance reporting scripts saved!\")\n",
    "print(f\"✓ SQL queries: 'performance_reporting_queries.sql'\")\n",
    "print(f\"✓ Python script: 'performance_reporting_script.py'\")\n",
    "\n",
    "print(f\"\\nDataset ready for performance evaluation and automated reporting!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd342c7e-291e-445e-ada6-01a95f3b415f",
   "metadata": {},
   "source": [
    "## Initial Analysis of Your Generated Data\n",
    "### Immediate Insights\n",
    "Data Quality: Synthetic data has realistic variance and correlations\n",
    "Completeness: All necessary KPIs are captured for comprehensive evaluation\n",
    "Scalability: Structure supports both individual and aggregate analysis\n",
    "Automation Ready: SQL queries and Python scripts are also provided\n",
    "### Performance Distribution\n",
    "Synthetic data follows a realistic performance distribution:\n",
    "Exceptional: 15% of interns\n",
    "High: 35%\n",
    "Medium: 35%\n",
    "Low: 15%\n",
    "This creates a balanced bell curve distribution that mirrors real-world performance patterns.\n",
    "### KPI Performance by Tier\n",
    "From the summary, we can see clear differentiation:\n",
    "Tier\t     Completion Rate\t   Quality Score\t    Performance Score\n",
    "Exceptional\t ~85%\t               ~9.0/10\t            High 80s-90s\n",
    "High\t     ~85%\t               ~8.0/10\t            Mid 80s\n",
    "Medium\t     ~70%\t               ~6.5/10\t            Low 70s\n",
    "Low\t         ~70%\t               ~5.0/10\t            Low 60s\n",
    "### Department Performance\n",
    "The data shows variation across departments, which could indicate:\n",
    "Different evaluation standards\n",
    "Varying task difficulty\n",
    "Department-specific challenges\n",
    "### Task Complexity Analysis\n",
    "The task types have well-defined complexity levels:\n",
    "High complexity: Code Development (4/5)\n",
    "Medium complexity: Data Analysis, Research (3/5)\n",
    "Low complexity: Report Writing, Presentation, Testing, Documentation (1-2/5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78727d3e-d042-4e79-b7ab-68633ab9ec29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
