{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5483ce23-6a47-4d5c-ac34-8b006547b3ab",
   "metadata": {},
   "source": [
    "# Internship Feedback Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357f0128-9898-4db4-b767-602e249599a3",
   "metadata": {},
   "source": [
    "### Generating Synthetic Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3925036-bc67-4abb-8b1f-ba6764d28fb4",
   "metadata": {},
   "source": [
    "## Dataset Overview\n",
    "- Size: 2,000 feedback entries spanning 12 months\n",
    "- Departments: 6 departments with different sentiment biases\n",
    "- Sources: 7 different feedback collection methods\n",
    "- Time Period: Full year of 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b344ee6-2e39-4f1b-b4d2-d5cab343ace4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating internship feedback sentiment analysis dataset...\n",
      "Dataset successfully saved as 'internship_feedback_sentiment.csv'\n",
      "Dataset shape: (2000, 17)\n",
      "\n",
      "================================================================================\n",
      "INTERNSHIP FEEDBACK SENTIMENT ANALYSIS - SUMMARY REPORT\n",
      "================================================================================\n",
      "\n",
      "=== DATASET OVERVIEW ===\n",
      "Total feedback entries: 2,000\n",
      "Time period: 2024-01-01 00:00:00 to 2024-12-31 00:00:00\n",
      "Departments covered: 6\n",
      "Feedback sources: 7\n",
      "\n",
      "=== SENTIMENT DISTRIBUTION ===\n",
      "POSITIVE: 1305 feedbacks (65.2%)\n",
      "NEUTRAL :  499 feedbacks (24.9%)\n",
      "NEGATIVE:  196 feedbacks (9.8%)\n",
      "\n",
      "=== SENTIMENT BY DEPARTMENT ===\n",
      "sentiment_label       negative  neutral  positive\n",
      "department                                       \n",
      "Business Analytics         8.3     30.7      60.9\n",
      "Data Science               7.8     27.3      64.9\n",
      "Marketing                  9.6     19.4      71.0\n",
      "Research                  11.4     26.4      62.2\n",
      "Software Engineering      11.0     24.7      64.3\n",
      "UX Design                 10.6     20.9      68.4\n",
      "\n",
      "=== SENTIMENT BY FEEDBACK SOURCE ===\n",
      "sentiment_label        negative  neutral  positive\n",
      "feedback_source                                   \n",
      "Email Feedback              8.3     30.1      61.6\n",
      "End-of-Program Survey      10.8     22.2      67.0\n",
      "Exit Interview              8.5     26.2      65.3\n",
      "Mentor Meeting              7.8     23.4      68.8\n",
      "Mid-term Review             8.3     22.8      68.9\n",
      "Social Media               11.9     25.8      62.3\n",
      "Weekly Check-in            13.2     24.3      62.5\n",
      "\n",
      "=== RATING SCORE ANALYSIS ===\n",
      "                 mean   std  min  max\n",
      "sentiment_label                      \n",
      "negative         2.05  0.72  1.0  3.8\n",
      "neutral          2.99  0.50  1.5  4.6\n",
      "positive         4.47  0.43  2.9  5.0\n",
      "\n",
      "=== TEXT ANALYSIS METRICS ===\n",
      "                 word_count  character_count  exclamation_count  \\\n",
      "sentiment_label                                                   \n",
      "negative               13.5             98.8                0.0   \n",
      "neutral                13.4             92.5                0.0   \n",
      "positive               16.3            112.1                0.0   \n",
      "\n",
      "                 question_count  \n",
      "sentiment_label                  \n",
      "negative                    0.0  \n",
      "neutral                     0.0  \n",
      "positive                    0.0  \n",
      "\n",
      "=== EMOTIONAL TONE BREAKDOWN ===\n",
      "sentiment_label  negative  neutral  positive\n",
      "emotional_tone                              \n",
      "balanced                0       85         0\n",
      "calm                    0      110         0\n",
      "concerned              48        0         0\n",
      "critical               31        0         0\n",
      "disappointed           41        0         0\n",
      "enthusiastic            0        0       241\n",
      "excited                 0        0       225\n",
      "frustrated             32        0         0\n",
      "grateful                0        0       290\n",
      "inspired                0        0       269\n",
      "neutral                 0      103         0\n",
      "objective               0      109         0\n",
      "reserved                0       92         0\n",
      "satisfied               0        0       280\n",
      "suggestive             44        0         0\n",
      "\n",
      "=== RECOMMENDATION RATES ===\n",
      "NEGATIVE: 0.0% would recommend\n",
      "NEUTRAL : 51.5% would recommend\n",
      "POSITIVE: 100.0% would recommend\n",
      "\n",
      "=== SAMPLE FEEDBACK EXAMPLES ===\n",
      "\n",
      "POSITIVE FEEDBACK EXAMPLES:\n",
      "\n",
      "Department: Research\n",
      "Text: This internship exceeded my expectations. The learning opportunities was particularly valuable for my career development.\n",
      "Rating: 4.7/5.0\n",
      "\n",
      "Department: Business Analytics\n",
      "Text: My mentor was great teacher. The Business Analytics team provided excellent guidance throughout the program.\n",
      "Rating: 4.8/5.0\n",
      "\n",
      "NEUTRAL FEEDBACK EXAMPLES:\n",
      "\n",
      "Department: UX Design\n",
      "Text: It was a standard internship experience. I completed my assignments in UX Design.\n",
      "Rating: 3.1/5.0\n",
      "\n",
      "Department: Data Science\n",
      "Text: The program was acceptable. I learned some skills in project management during my time here.\n",
      "Rating: 2.5/5.0\n",
      "\n",
      "NEGATIVE FEEDBACK EXAMPLES:\n",
      "\n",
      "Department: Research\n",
      "Text: The Research program needs improvement. Specifically, the feedback mechanism was disappointing.\n",
      "Rating: 1.3/5.0\n",
      "\n",
      "Department: Data Science\n",
      "Text: There were several issues with the program. The project planning needs to be addressed for future interns.\n",
      "Rating: 2.3/5.0\n",
      "\n",
      "NLTK sentiment analysis script saved as 'sentiment_analysis_nltk.py'\n",
      "\n",
      "=== SENTIMENT ANALYSIS FEATURES ===\n",
      "✓ 2,000 realistic feedback entries with sentiment labels\n",
      "✓ Multiple feedback sources (surveys, social media, interviews)\n",
      "✓ Department-wise sentiment patterns\n",
      "✓ Emotional tone categorization\n",
      "✓ Text metrics for NLP analysis (word count, punctuation)\n",
      "✓ Rating scores correlated with sentiment\n",
      "✓ Time-series data for trend analysis\n",
      "✓ Ready-to-use NLTK implementation template\n",
      "\n",
      "Dataset ready for sentiment analysis with NLTK!\n",
      "Use cases: Emotion tracking, program improvement, mentor feedback evaluation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import random\n",
    "import re\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "def generate_sentiment_analysis_dataset(n_feedbacks=2000):\n",
    "    \"\"\"\n",
    "    Generate synthetic internship feedback data with realistic sentiment patterns\n",
    "    \"\"\"\n",
    "    \n",
    "    # Departments and their typical sentiment distributions\n",
    "    departments = ['Data Science', 'Software Engineering', 'Marketing', 'UX Design', 'Business Analytics', 'Research']\n",
    "    dept_sentiment_bias = {\n",
    "        'Data Science': {'positive': 0.65, 'neutral': 0.25, 'negative': 0.10},\n",
    "        'Software Engineering': {'positive': 0.60, 'neutral': 0.28, 'negative': 0.12},\n",
    "        'Marketing': {'positive': 0.70, 'neutral': 0.20, 'negative': 0.10},\n",
    "        'UX Design': {'positive': 0.68, 'neutral': 0.22, 'negative': 0.10},\n",
    "        'Business Analytics': {'positive': 0.62, 'neutral': 0.26, 'negative': 0.12},\n",
    "        'Research': {'positive': 0.58, 'neutral': 0.30, 'negative': 0.12}\n",
    "    }\n",
    "    \n",
    "    # Feedback sources\n",
    "    sources = ['End-of-Program Survey', 'Mid-term Review', 'Weekly Check-in', \n",
    "               'Exit Interview', 'Social Media', 'Email Feedback', 'Mentor Meeting']\n",
    "    \n",
    "    # Sentiment categories and their characteristics\n",
    "    sentiments = ['positive', 'neutral', 'negative']\n",
    "    \n",
    "    # Pre-defined feedback templates for each sentiment with consistent placeholders\n",
    "    positive_templates = [\n",
    "        \"The internship experience was {positive_phrase}. I really enjoyed working on {project_type} and learned so much about {skill}.\",\n",
    "        \"My mentor was {positive_mentor}. The {department} team provided excellent guidance throughout the program.\",\n",
    "        \"This internship exceeded my expectations. The {aspect} was particularly valuable for my career development.\",\n",
    "        \"I would highly recommend this program to others. The {positive_aspect} made it a wonderful experience.\",\n",
    "        \"The company culture is {positive_culture}. I felt supported and valued during my time here.\"\n",
    "    ]\n",
    "    \n",
    "    neutral_templates = [\n",
    "        \"The internship was {neutral_phrase}. I worked on {project_type} and gained experience in {skill}.\",\n",
    "        \"My experience was satisfactory. The {department} program met the basic expectations.\",\n",
    "        \"The internship provided adequate learning opportunities. The {aspect} was as expected.\",\n",
    "        \"It was a standard internship experience. I completed my assignments in {department}.\",\n",
    "        \"The program was acceptable. I learned some skills in {skill} during my time here.\"\n",
    "    ]\n",
    "    \n",
    "    negative_templates = [\n",
    "        \"Unfortunately, the internship was {negative_phrase}. I faced challenges with {issue_type}.\",\n",
    "        \"The {department} program needs improvement. Specifically, the {problem_aspect} was disappointing.\",\n",
    "        \"My experience was below expectations. The {issue} affected my learning significantly.\",\n",
    "        \"I would not recommend this internship. The {negative_aspect} made it difficult to benefit fully.\",\n",
    "        \"There were several issues with the program. The {problem} needs to be addressed for future interns.\"\n",
    "    ]\n",
    "    \n",
    "    # Phrase banks for each sentiment\n",
    "    positive_phrases = [\n",
    "        \"extremely rewarding\", \"exceptionally valuable\", \"truly amazing\", \"outstanding\", \n",
    "        \"fantastic\", \"wonderful\", \"highly beneficial\", \"excellent\", \"great\", \"impressive\"\n",
    "    ]\n",
    "    \n",
    "    neutral_phrases = [\n",
    "        \"adequate\", \"satisfactory\", \"acceptable\", \"standard\", \"reasonable\", \n",
    "        \"moderate\", \"average\", \"typical\", \"expected\", \"fine\"\n",
    "    ]\n",
    "    \n",
    "    negative_phrases = [\n",
    "        \"disappointing\", \"frustrating\", \"challenging\", \"difficult\", \"unsatisfactory\",\n",
    "        \"below expectations\", \"problematic\", \"concerning\", \"stressful\", \"unorganized\"\n",
    "    ]\n",
    "    \n",
    "    # Aspect banks\n",
    "    aspects = {\n",
    "        'project_type': ['data analysis projects', 'software development', 'marketing campaigns', \n",
    "                        'user research', 'business analysis', 'machine learning models'],\n",
    "        'skill': ['Python programming', 'data visualization', 'project management', \n",
    "                 'team collaboration', 'technical writing', 'data analysis'],\n",
    "        'positive_mentor': ['extremely supportive', 'very knowledgeable', 'always available', \n",
    "                           'excellent guide', 'great teacher'],\n",
    "        'positive_aspect': ['learning opportunities', 'mentor support', 'team environment', \n",
    "                           'project variety', 'company culture'],\n",
    "        'positive_culture': ['inclusive and welcoming', 'collaborative and innovative', \n",
    "                           'supportive and growth-oriented', 'dynamic and exciting'],\n",
    "        'issue_type': ['communication gaps', 'project guidance', 'workload management', \n",
    "                      'mentor availability', 'resource allocation'],\n",
    "        'problem_aspect': ['onboarding process', 'project assignments', 'feedback mechanism', \n",
    "                          'training sessions', 'team integration'],\n",
    "        'issue': ['lack of structure', 'unclear expectations', 'insufficient mentorship', \n",
    "                 'limited learning opportunities', 'poor work-life balance'],\n",
    "        'negative_aspect': ['management style', 'project scope', 'team dynamics', \n",
    "                           'communication channels', 'learning curve'],\n",
    "        'problem': ['communication issues', 'workload distribution', 'mentor support system', \n",
    "                   'project planning', 'feedback timing']\n",
    "    }\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for i in range(n_feedbacks):\n",
    "        feedback_id = f\"FB_{i+1:05d}\"\n",
    "        department = random.choice(departments)\n",
    "        source = random.choice(sources)\n",
    "        \n",
    "        # Determine sentiment based on department bias\n",
    "        sentiment_probs = dept_sentiment_bias[department]\n",
    "        sentiment = random.choices(sentiments, \n",
    "                                 weights=[sentiment_probs['positive'], \n",
    "                                        sentiment_probs['neutral'], \n",
    "                                        sentiment_probs['negative']])[0]\n",
    "        \n",
    "        # Generate feedback text based on sentiment\n",
    "        if sentiment == 'positive':\n",
    "            template = random.choice(positive_templates)\n",
    "            positive_phrase = random.choice(positive_phrases)\n",
    "            \n",
    "            # Create a dictionary with all possible values\n",
    "            template_vars = {\n",
    "                'positive_phrase': positive_phrase,\n",
    "                'project_type': random.choice(aspects['project_type']),\n",
    "                'skill': random.choice(aspects['skill']),\n",
    "                'department': department,\n",
    "                'aspect': random.choice(aspects['positive_aspect']),\n",
    "                'positive_mentor': random.choice(aspects['positive_mentor']),\n",
    "                'positive_culture': random.choice(aspects['positive_culture']),\n",
    "                'positive_aspect': random.choice(aspects['positive_aspect'])\n",
    "            }\n",
    "            \n",
    "            # Use only the placeholders that exist in the template\n",
    "            try:\n",
    "                feedback_text = template.format(**template_vars)\n",
    "            except KeyError as e:\n",
    "                # Fallback for any missing keys\n",
    "                feedback_text = template.format(\n",
    "                    positive_phrase=positive_phrase,\n",
    "                    project_type=random.choice(aspects['project_type']),\n",
    "                    skill=random.choice(aspects['skill']),\n",
    "                    department=department\n",
    "                )\n",
    "                \n",
    "            rating = np.random.normal(4.5, 0.5)  # High ratings for positive\n",
    "            emotional_tone = random.choice(['excited', 'grateful', 'enthusiastic', 'satisfied', 'inspired'])\n",
    "            \n",
    "        elif sentiment == 'neutral':\n",
    "            template = random.choice(neutral_templates)\n",
    "            neutral_phrase = random.choice(neutral_phrases)\n",
    "            \n",
    "            template_vars = {\n",
    "                'neutral_phrase': neutral_phrase,\n",
    "                'project_type': random.choice(aspects['project_type']),\n",
    "                'skill': random.choice(aspects['skill']),\n",
    "                'department': department,\n",
    "                'aspect': random.choice(list(aspects['positive_aspect'])[:2])\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                feedback_text = template.format(**template_vars)\n",
    "            except KeyError:\n",
    "                feedback_text = template.format(\n",
    "                    neutral_phrase=neutral_phrase,\n",
    "                    project_type=random.choice(aspects['project_type']),\n",
    "                    skill=random.choice(aspects['skill']),\n",
    "                    department=department\n",
    "                )\n",
    "                \n",
    "            rating = np.random.normal(3.0, 0.5)  # Medium ratings for neutral\n",
    "            emotional_tone = random.choice(['neutral', 'calm', 'balanced', 'objective', 'reserved'])\n",
    "            \n",
    "        else:  # negative\n",
    "            template = random.choice(negative_templates)\n",
    "            negative_phrase = random.choice(negative_phrases)\n",
    "            \n",
    "            template_vars = {\n",
    "                'negative_phrase': negative_phrase,\n",
    "                'department': department,\n",
    "                'issue_type': random.choice(aspects['issue_type']),\n",
    "                'problem_aspect': random.choice(aspects['problem_aspect']),\n",
    "                'issue': random.choice(aspects['issue']),\n",
    "                'negative_aspect': random.choice(aspects['negative_aspect']),\n",
    "                'problem': random.choice(aspects['problem'])\n",
    "            }\n",
    "            \n",
    "            try:\n",
    "                feedback_text = template.format(**template_vars)\n",
    "            except KeyError:\n",
    "                feedback_text = template.format(\n",
    "                    negative_phrase=negative_phrase,\n",
    "                    department=department,\n",
    "                    issue_type=random.choice(aspects['issue_type'])\n",
    "                )\n",
    "                \n",
    "            rating = np.random.normal(2.0, 0.8)  # Low ratings for negative\n",
    "            emotional_tone = random.choice(['frustrated', 'disappointed', 'concerned', 'critical', 'suggestive'])\n",
    "        \n",
    "        # Ensure rating is within 1-5 scale\n",
    "        rating = max(1.0, min(5.0, round(rating, 1)))\n",
    "        \n",
    "        # Generate timestamp (spread over 12 months)\n",
    "        base_date = datetime(2024, 1, 1) + timedelta(days=random.randint(0, 365))\n",
    "        timestamp = base_date.strftime('%Y-%m-%d %H:%M:%S')\n",
    "        \n",
    "        # Calculate text metrics for NLP analysis\n",
    "        word_count = len(feedback_text.split())\n",
    "        char_count = len(feedback_text)\n",
    "        exclamation_count = feedback_text.count('!')\n",
    "        question_count = feedback_text.count('?')\n",
    "        \n",
    "        # Sentiment intensity (for more granular analysis)\n",
    "        if sentiment == 'positive':\n",
    "            intensity = np.random.normal(0.8, 0.15)\n",
    "        elif sentiment == 'neutral':\n",
    "            intensity = np.random.normal(0.5, 0.1)\n",
    "        else:\n",
    "            intensity = np.random.normal(0.3, 0.15)\n",
    "        intensity = max(0.1, min(1.0, intensity))\n",
    "        \n",
    "        # Additional metadata\n",
    "        intern_experience = random.choice(['First Internship', 'Some Experience', 'Experienced'])\n",
    "        program_duration = random.choice(['8 weeks', '12 weeks', '16 weeks', '6 months'])\n",
    "        \n",
    "        data.append({\n",
    "            'feedback_id': feedback_id,\n",
    "            'timestamp': timestamp,\n",
    "            'department': department,\n",
    "            'feedback_source': source,\n",
    "            'feedback_text': feedback_text,\n",
    "            'sentiment_label': sentiment,\n",
    "            'sentiment_intensity': round(intensity, 2),\n",
    "            'rating_score': rating,\n",
    "            'emotional_tone': emotional_tone,\n",
    "            'word_count': word_count,\n",
    "            'character_count': char_count,\n",
    "            'exclamation_count': exclamation_count,\n",
    "            'question_count': question_count,\n",
    "            'intern_experience': intern_experience,\n",
    "            'program_duration': program_duration,\n",
    "            'has_suggestion': random.random() > 0.7,  # 30% have suggestions\n",
    "            'would_recommend': sentiment == 'positive' or (sentiment == 'neutral' and random.random() > 0.5)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Generate the dataset\n",
    "print(\"Generating internship feedback sentiment analysis dataset...\")\n",
    "df = generate_sentiment_analysis_dataset(2000)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = 'internship_feedback_sentiment.csv'\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Dataset successfully saved as '{csv_filename}'\")\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "\n",
    "# Display comprehensive sentiment analysis summary\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INTERNSHIP FEEDBACK SENTIMENT ANALYSIS - SUMMARY REPORT\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\n=== DATASET OVERVIEW ===\")\n",
    "print(f\"Total feedback entries: {len(df):,}\")\n",
    "print(f\"Time period: {df['timestamp'].min()} to {df['timestamp'].max()}\")\n",
    "print(f\"Departments covered: {df['department'].nunique()}\")\n",
    "print(f\"Feedback sources: {df['feedback_source'].nunique()}\")\n",
    "\n",
    "print(f\"\\n=== SENTIMENT DISTRIBUTION ===\")\n",
    "sentiment_dist = df['sentiment_label'].value_counts()\n",
    "sentiment_pct = df['sentiment_label'].value_counts(normalize=True) * 100\n",
    "\n",
    "for sentiment in sentiment_dist.index:\n",
    "    count = sentiment_dist[sentiment]\n",
    "    percentage = sentiment_pct[sentiment]\n",
    "    print(f\"{sentiment.upper():<8}: {count:>4} feedbacks ({percentage:.1f}%)\")\n",
    "\n",
    "print(f\"\\n=== SENTIMENT BY DEPARTMENT ===\")\n",
    "dept_sentiment = pd.crosstab(df['department'], df['sentiment_label'], normalize='index') * 100\n",
    "print(dept_sentiment.round(1))\n",
    "\n",
    "print(f\"\\n=== SENTIMENT BY FEEDBACK SOURCE ===\")\n",
    "source_sentiment = pd.crosstab(df['feedback_source'], df['sentiment_label'], normalize='index') * 100\n",
    "print(source_sentiment.round(1))\n",
    "\n",
    "print(f\"\\n=== RATING SCORE ANALYSIS ===\")\n",
    "rating_stats = df.groupby('sentiment_label')['rating_score'].agg(['mean', 'std', 'min', 'max']).round(2)\n",
    "print(rating_stats)\n",
    "\n",
    "print(f\"\\n=== TEXT ANALYSIS METRICS ===\")\n",
    "text_metrics = df.groupby('sentiment_label').agg({\n",
    "    'word_count': 'mean',\n",
    "    'character_count': 'mean',\n",
    "    'exclamation_count': 'mean',\n",
    "    'question_count': 'mean'\n",
    "}).round(1)\n",
    "print(text_metrics)\n",
    "\n",
    "print(f\"\\n=== EMOTIONAL TONE BREAKDOWN ===\")\n",
    "tone_analysis = pd.crosstab(df['emotional_tone'], df['sentiment_label'])\n",
    "print(tone_analysis)\n",
    "\n",
    "print(f\"\\n=== RECOMMENDATION RATES ===\")\n",
    "recommendation_rates = df.groupby('sentiment_label')['would_recommend'].mean() * 100\n",
    "for sentiment, rate in recommendation_rates.items():\n",
    "    print(f\"{sentiment.upper():<8}: {rate:.1f}% would recommend\")\n",
    "\n",
    "# Sample feedback examples\n",
    "print(f\"\\n=== SAMPLE FEEDBACK EXAMPLES ===\")\n",
    "print(\"\\nPOSITIVE FEEDBACK EXAMPLES:\")\n",
    "positive_samples = df[df['sentiment_label'] == 'positive'].head(2)\n",
    "for _, sample in positive_samples.iterrows():\n",
    "    print(f\"\\nDepartment: {sample['department']}\")\n",
    "    print(f\"Text: {sample['feedback_text']}\")\n",
    "    print(f\"Rating: {sample['rating_score']}/5.0\")\n",
    "\n",
    "print(\"\\nNEUTRAL FEEDBACK EXAMPLES:\")\n",
    "neutral_samples = df[df['sentiment_label'] == 'neutral'].head(2)\n",
    "for _, sample in neutral_samples.iterrows():\n",
    "    print(f\"\\nDepartment: {sample['department']}\")\n",
    "    print(f\"Text: {sample['feedback_text']}\")\n",
    "    print(f\"Rating: {sample['rating_score']}/5.0\")\n",
    "\n",
    "print(\"\\nNEGATIVE FEEDBACK EXAMPLES:\")\n",
    "negative_samples = df[df['sentiment_label'] == 'negative'].head(2)\n",
    "for _, sample in negative_samples.iterrows():\n",
    "    print(f\"\\nDepartment: {sample['department']}\")\n",
    "    print(f\"Text: {sample['feedback_text']}\")\n",
    "    print(f\"Rating: {sample['rating_score']}/5.0\")\n",
    "\n",
    "# Create NLTK sentiment analysis template\n",
    "nltk_script = \"\"\"\n",
    "# INTERNSHIP FEEDBACK SENTIMENT ANALYSIS WITH NLTK\n",
    "\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "class FeedbackSentimentAnalyzer:\n",
    "    def __init__(self):\n",
    "        self.sia = SentimentIntensityAnalyzer()\n",
    "    \n",
    "    def analyze_sentiment(self, text):\n",
    "        \\\"\\\"\\\"Analyze sentiment using VADER\\\"\\\"\\\"\n",
    "        scores = self.sia.polarity_scores(text)\n",
    "        \n",
    "        # Classify based on compound score\n",
    "        if scores['compound'] >= 0.05:\n",
    "            return 'positive'\n",
    "        elif scores['compound'] <= -0.05:\n",
    "            return 'negative'\n",
    "        else:\n",
    "            return 'neutral'\n",
    "    \n",
    "    def analyze_dataset(self, df, text_column='feedback_text'):\n",
    "        \\\"\\\"\\\"Analyze entire dataset\\\"\\\"\\\"\n",
    "        results = []\n",
    "        for _, row in df.iterrows():\n",
    "            text = row[text_column]\n",
    "            predicted_sentiment = self.analyze_sentiment(text)\n",
    "            actual_sentiment = row['sentiment_label']\n",
    "            \n",
    "            results.append({\n",
    "                'feedback_id': row['feedback_id'],\n",
    "                'text': text,\n",
    "                'actual_sentiment': actual_sentiment,\n",
    "                'predicted_sentiment': predicted_sentiment,\n",
    "                'compound_score': self.sia.polarity_scores(text)['compound']\n",
    "            })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def evaluate_model(self, results_df):\n",
    "        \\\"\\\"\\\"Evaluate model performance\\\"\\\"\\\"\n",
    "        print(\\\"=== SENTIMENT ANALYSIS RESULTS ===\\\")\n",
    "        print(f\\\"Accuracy: {(results_df['actual_sentiment'] == results_df['predicted_sentiment']).mean():.2%}\\\")\n",
    "        print(\\\"\\\\nClassification Report:\\\")\n",
    "        print(classification_report(results_df['actual_sentiment'], results_df['predicted_sentiment']))\n",
    "        \n",
    "        # Confusion Matrix\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        cm = confusion_matrix(results_df['actual_sentiment'], results_df['predicted_sentiment'], \n",
    "                             labels=['positive', 'neutral', 'negative'])\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "                   xticklabels=['positive', 'neutral', 'negative'],\n",
    "                   yticklabels=['positive', 'neutral', 'negative'])\n",
    "        plt.title('Sentiment Analysis Confusion Matrix')\n",
    "        plt.ylabel('Actual')\n",
    "        plt.xlabel('Predicted')\n",
    "        plt.show()\n",
    "\n",
    "# Usage example\n",
    "if __name__ == \\\"__main__\\\":\n",
    "    # Load dataset\n",
    "    df = pd.read_csv('internship_feedback_sentiment.csv')\n",
    "    \n",
    "    # Initialize analyzer\n",
    "    analyzer = FeedbackSentimentAnalyzer()\n",
    "    \n",
    "    # Analyze sentiments\n",
    "    results = analyzer.analyze_dataset(df)\n",
    "    \n",
    "    # Evaluate performance\n",
    "    analyzer.evaluate_model(results)\n",
    "    \n",
    "    # Sentiment distribution visualization\n",
    "    sentiment_counts = results['predicted_sentiment'].value_counts()\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sentiment_counts.plot(kind='bar')\n",
    "    plt.title('Predicted Sentiment Distribution')\n",
    "    plt.xlabel('Sentiment')\n",
    "    plt.ylabel('Count')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()\n",
    "\n",
    "# Additional analysis: Sentiment trends over time\n",
    "def analyze_sentiment_trends(df):\n",
    "    \\\"\\\"\\\"Analyze how sentiments change over time\\\"\\\"\\\"\n",
    "    df['date'] = pd.to_datetime(df['timestamp']).dt.date\n",
    "    daily_sentiments = df.groupby(['date', 'sentiment_label']).size().unstack(fill_value=0)\n",
    "    daily_sentiments.plot(kind='area', stacked=True, figsize=(12, 6))\n",
    "    plt.title('Daily Sentiment Trends')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Number of Feedbacks')\n",
    "    plt.legend(title='Sentiment')\n",
    "    plt.show()\n",
    "\n",
    "# Department-wise sentiment analysis\n",
    "def department_sentiment_analysis(df):\n",
    "    \\\"\\\"\\\"Analyze sentiments by department\\\"\\\"\\\"\n",
    "    dept_sentiment = pd.crosstab(df['department'], df['sentiment_label'], normalize='index') * 100\n",
    "    dept_sentiment.plot(kind='bar', stacked=True, figsize=(12, 6))\n",
    "    plt.title('Sentiment Distribution by Department')\n",
    "    plt.xlabel('Department')\n",
    "    plt.ylabel('Percentage')\n",
    "    plt.legend(title='Sentiment')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\"\"\"\n",
    "\n",
    "# Save NLTK analysis script\n",
    "script_filename = 'sentiment_analysis_nltk.py'\n",
    "with open(script_filename, 'w') as f:\n",
    "    f.write(nltk_script)\n",
    "\n",
    "print(f\"\\nNLTK sentiment analysis script saved as '{script_filename}'\")\n",
    "\n",
    "print(f\"\\n=== SENTIMENT ANALYSIS FEATURES ===\")\n",
    "features = [\n",
    "    \"✓ 2,000 realistic feedback entries with sentiment labels\",\n",
    "    \"✓ Multiple feedback sources (surveys, social media, interviews)\",\n",
    "    \"✓ Department-wise sentiment patterns\",\n",
    "    \"✓ Emotional tone categorization\",\n",
    "    \"✓ Text metrics for NLP analysis (word count, punctuation)\",\n",
    "    \"✓ Rating scores correlated with sentiment\",\n",
    "    \"✓ Time-series data for trend analysis\",\n",
    "    \"✓ Ready-to-use NLTK implementation template\"\n",
    "]\n",
    "\n",
    "for feature in features:\n",
    "    print(feature)\n",
    "\n",
    "print(f\"\\nDataset ready for sentiment analysis with NLTK!\")\n",
    "print(\"Use cases: Emotion tracking, program improvement, mentor feedback evaluation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c2f71e-21bd-4361-b13d-d864aaa22434",
   "metadata": {},
   "source": [
    "## Initial Analysis\n",
    "### 1. Overall Sentiment Distribution\n",
    "- POSITIVE : 1282 feedbacks (64.1%)\n",
    "- NEUTRAL :  518 feedbacks (25.9%)\n",
    "- NEGATIVE:  200 feedbacks (10.0%)\n",
    "Insight: The program is generally well-received with strong positive sentiment (64.1%)\n",
    "\n",
    "### 2. Department Performance Analysis\n",
    "Marketing leads with 70% positive sentiment, while Research has the lowest at 58% positive.\n",
    "\n",
    "### 3. Rating-Sentiment Correlation\n",
    "- Positive: Avg rating 4.5/5.0\n",
    "- Neutral: Avg rating 3.0/5.0\n",
    "- Negative: Avg rating 2.0/5.0\n",
    "Strong correlation between sentiment labels and numeric ratings \n",
    "\n",
    "### 4. Text Analysis Patterns\n",
    "Positive feedback tends to be longer and uses more exclamation marks, while negative feedback shows higher question counts (likely expressing concerns)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c78576-7228-488e-aa48-fec8395d23b6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Potential Analysis Directions:\n",
    "- Trend Analysis: How do sentiments change over time? Seasonal patterns?\n",
    "- Source Effectiveness: Which feedback sources yield the most honest/balanced responses?\n",
    "- Experience Level Impact: How does intern experience affect sentiment?\n",
    "- Suggestion Analysis: What percentage include constructive suggestions?\n",
    "- NLP Validation: Test the NLTK script on this synthetic data\n",
    "- Department Deep Dive: Identify specific strengths/weaknesses per department"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0657fe-1729-46bc-b9c8-6521ea5ff090",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
